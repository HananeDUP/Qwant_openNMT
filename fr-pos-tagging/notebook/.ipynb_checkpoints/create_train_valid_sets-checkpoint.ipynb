{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sentences_from_txt(file_name):\n",
    "    sentences=[]\n",
    "    f = open(file_name, 'rt')\n",
    "    sentences_words=[]\n",
    "    for line in f:\n",
    "        sentences.append(line)\n",
    "    f.close()\n",
    "    return sentences\n",
    "\n",
    "def save_to_txt(sentences_array,file_output_name):\n",
    "    if os.path.isfile(file_output_name):\n",
    "        os.remove(file_output_name)\n",
    "    with open(file_output_name, \"a\") as a_file:\n",
    "        for elem in sentences_array:\n",
    "            a_file.write(elem)\n",
    "            a_file.write(\"\\n\")\n",
    "    a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate train and valid datasets for both words and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words=get_all_sentences_from_txt(\"../dataset/raw2/wiki_words_bitext_2.txt\")\n",
    "train_tags=get_all_sentences_from_txt(\"../dataset/raw2/wiki_tags_bitext_2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27822\n"
     ]
    }
   ],
   "source": [
    "train_words=get_all_sentences_from_txt(\"../dataset/raw2/wiki_words_bitext_2.txt\")\n",
    "train_tags=get_all_sentences_from_txt(\"../dataset/raw2/wiki_tags_bitext_2.txt\")\n",
    "\n",
    "train_words=[elem[:-1] for elem in train_words] #A the end of each line ==> \\n\n",
    "train_tags=[elem[:-1] for elem in train_tags]\n",
    "print(len(train_words))\n",
    "\n",
    "#index list 1000 values\n",
    "# list_valid=np.random.random_integers(0,len(train_words)-1,1000)\n",
    "list_valid=np.random.randint(0,len(train_words)-1,3000)\n",
    "\n",
    "valid_words=[]\n",
    "valid_tags=[]\n",
    "for idx in list_valid:\n",
    "    valid_words.append(train_words[idx])\n",
    "    valid_tags.append(train_tags[idx])\n",
    "\n",
    "save_to_txt(valid_words,\"../dataset/train_valid/wiki_valid_words_bitext.txt\")\n",
    "save_to_txt(valid_tags,\"../dataset/train_valid/wiki_valid_tags_bitext.txt\")\n",
    "\n",
    "#the new train without 1000 lines\n",
    "for idx in sorted(list_valid, reverse=True):\n",
    "    train_words.pop(idx)\n",
    "    train_tags.pop(idx)\n",
    "\n",
    "save_to_txt(train_words,\"../dataset/train_valid/wiki_train_words_bitext.txt\")\n",
    "save_to_txt(train_tags,\"../dataset/train_valid/wiki_train_tags_bitext.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Vocabs: Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# # stop_words=stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from time import time\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(cv_vectorizer,data):\n",
    "    t0=time()\n",
    "    print(\"in vectorizer fit_transform\",dt.datetime.fromtimestamp(t0))\n",
    "    cv_data = cv_vectorizer.fit_transform(data)\n",
    "    print(time()-t0)\n",
    "    print(\"%0.3fs.\" % (time() - t0),round((time() - t0)/60,1),\"min\")\n",
    "    return cv_vectorizer,cv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in vectorizer fit_transform 2020-08-02 20:26:49.962890\n",
      "1.7129995822906494\n",
      "1.714s. 0.0 min\n"
     ]
    }
   ],
   "source": [
    "train_words_cv=get_all_sentences_from_txt(\"../dataset/train_valid/wiki_train_words_bitext.txt\")\n",
    "train_words_cv=[elem[:-1] for elem in train_words_cv]\n",
    "cv_wiki = CountVectorizer(max_features=50000,analyzer='word',lowercase=False)\n",
    "cv_vectorizer,cv_data=vectorizer(cv_wiki,train_words_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs=cv_vectorizer.vocabulary_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_txt(vocabs,\"../dataset/train_valid/src-wiki-train-vocab.txt.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Vocabs: Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in vectorizer fit_transform 2020-08-02 20:49:18.175570\n",
      "2.213998556137085\n",
      "2.215s. 0.0 min\n"
     ]
    }
   ],
   "source": [
    "cv_wiki_char = CountVectorizer(max_features=50000,analyzer='char',lowercase=False)\n",
    "cv_wiki_char,cv_data_char=vectorizer(cv_wiki_char,train_words_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "print(len(cv_wiki_char.vocabulary_))\n",
    "vocabs_char=cv_wiki_char.vocabulary_.keys()\n",
    "save_to_txt(vocabs_char,\"../dataset/train_valid/wiki-src-train-tkt-vocab.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
